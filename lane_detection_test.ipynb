{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stab project \n",
    "# detection of lane lines\n",
    "# ver. 0.0.1\n",
    "(c) 2019 Dr.Evstigneev N.M.\n",
    " \n",
    "Usage: select propper window of interest by double clicking on region points in sequence:\n",
    "\n",
    "   (1)--(2)\n",
    "\n",
    "\n",
    "\n",
    "(0)---------(3)\n",
    "\n",
    "To start press 'w' or 's' depending on projection type\n",
    "\n",
    "To change threshold press '5' or '6'\n",
    "\n",
    "to quit press 'q'\n",
    "\n",
    "Other parameters: see code\n",
    "\n",
    "In addition one can add at least combinations of filters and selction of best from obvious parameters of lanes, i.e. curvature and distance between points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.14 |Anaconda custom (64-bit)| (default, Oct 16 2017, 17:29:19) \n",
      "[GCC 7.2.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "print sys.version\n",
    "\n",
    "cv2.__version__\n",
    "#WARINING! Tested for Python 2.7.14, cv2 ver. '3.4.0'\n",
    "from scipy import signal\n",
    "#for debug\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pnts=[[0,0],[0,0],[0,0],[0,0]];\n",
    "click=0;\n",
    "set_poly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class for 2-nd order polyninomial with given value of derivative at given point\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "class poly_fixed_der:\n",
    "    def __init__(self, zero_x_point = 0, derivative_value = 0):\n",
    "        self.zero_x_point = zero_x_point\n",
    "        self.derivative_value = derivative_value\n",
    "        self.popt=[]\n",
    "        self.poly_is_fitted = False\n",
    "        \n",
    "    def set_zero_x_point(self, zero_x_point_local):\n",
    "        self.zero_x_point = zero_x_point_local\n",
    "    \n",
    "    def polynomial(self, x, a, b, c):\n",
    "        return a*np.float64(x)*np.float64(x)+(self.derivative_value - 2*a*self.zero_x_point)*np.float64(x)+c\n",
    "        \n",
    "    def polynomial_der(self, x, a, b, c):\n",
    "        return 2*a*np.float64(x)+(self.derivative_value - 2*a*self.zero_x_point)\n",
    "\n",
    "    \n",
    "    def fit(self, x_data, y_data):\n",
    "        self.popt, pcov = curve_fit(self.polynomial, x_data, y_data)\n",
    "        self.popt[1]=self.derivative_value - 2*self.popt[0]*self.zero_x_point\n",
    "        self.poly_is_fitted = True\n",
    "        \n",
    "    def ret(self, x_data):\n",
    "        if self.poly_is_fitted == True:\n",
    "            return self.polynomial(x_data, *self.popt)\n",
    "        else: \n",
    "            return 0\n",
    "    \n",
    "    def ret_der(self, x_data):\n",
    "        if self.poly_is_fitted == True:\n",
    "            return self.polynomial_der(x_data, *self.popt)\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def is_fitted(self):\n",
    "        return self.poly_is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_rectangle(event,x,y,flags,param):\n",
    "    global set_poly, pnts, click\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        if(set_poly==True):\n",
    "            pnts[click]=[x,y];\n",
    "            click+=1\n",
    "            if(click>3):\n",
    "                set_poly=False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_coordinates(rect_points, image_shape):\n",
    "    offset = min(image_shape[0]*0.85,280)\n",
    "    print rect_points[0][0] + offset\n",
    "    print rect_points[3][0] + offset\n",
    "    src = np.float32(rect_points)\n",
    "    \n",
    "#     img_change=[\n",
    "#         rect_points[0],\n",
    "#         [rect_points[0][0],rect_points[1][1]],\n",
    "#         [rect_points[3][0],rect_points[2][1]],\n",
    "#         rect_points[3]]\n",
    "    \n",
    "#     img_change=[\n",
    "#         [0,1600],\n",
    "#         [0,0],\n",
    "#         [700,0],\n",
    "#         [700,1600]]\n",
    "    \n",
    "    img_change=[\n",
    "    (rect_points[0][0] + offset, image_shape[0]),\n",
    "    (rect_points[0][0] + offset, 0),\n",
    "    (rect_points[3][0] - offset, 0),\n",
    "    (rect_points[3][0] - offset, image_shape[0])]\n",
    "    dst = np.float32(img_change)\n",
    "    print rect_points\n",
    "    print img_change\n",
    "    M = cv2.getPerspectiveTransform(src, dst) # The transformation matrix\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src) # Inverse transformation\n",
    "    return (M,Minv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial projection matrix\n",
    "M=np.eye(3,3)\n",
    "Minv=M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one can use lots of different filters and their combinations\n",
    "# i take only this one for demo purposes!!!\n",
    "# thresholds are modified by keyboard keys\n",
    "\n",
    "def detect_edges(img, pnts, thresh1=30, thresh2=150, thresh = 100):\n",
    "    mask = np.zeros((img.shape[0], img.shape[1]), dtype=\"uint8\")\n",
    "    cv2.fillConvexPoly(mask, pnts, 255)\n",
    "    masked = cv2.bitwise_and(img, img, mask=mask)\n",
    "    frame = masked\n",
    "    frame = cv2.threshold(masked, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    kernel_size = 5\n",
    "    edges1 = cv2.GaussianBlur(frame,(kernel_size, kernel_size),0)\n",
    "    #edges = cv2.Canny(edges1,thresh1,thresh2,apertureSize = 5, L2gradient=True)\n",
    "    edges = cv2.Sobel(edges1,cv2.CV_64F,1,0,ksize=3)\n",
    "    # edges = cv2.Scharr(edges1,cv2.CV_64F,1,0,)\n",
    "    frame = cv2.threshold(edges, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "    return frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_pointsP(img):\n",
    "#     lines = 0\n",
    "#     lines = cv2.HoughLinesP(np.uint8(img),1,np.pi/180,25)\n",
    "#     img = np.zeros(img.shape)\n",
    "#     if lines is not None:\n",
    "#         for x1,y1,x2,y2 in lines[0]:\n",
    "#             cv2.line(img,(x1,y1),(x2,y2),(10,10,10),2)\n",
    "    \n",
    "#     return img, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_points(img):\n",
    "#     lines = 0\n",
    "#     lines = cv2.HoughLines(np.uint8(img),1,np.pi/180,25)\n",
    "#     img = np.zeros(img.shape)\n",
    "#     if lines is not None:\n",
    "#         for zzz in lines:\n",
    "#             rho, theta = zzz[0]\n",
    "#             a = np.cos(theta)\n",
    "#             b = np.sin(theta)\n",
    "#             x0 = a*rho\n",
    "#             y0 = b*rho\n",
    "#             x1 = int(x0 + 1000*(-b))\n",
    "#             y1 = int(y0 + 1000*(a))\n",
    "#             x2 = int(x0 - 1000*(-b))\n",
    "#             y2 = int(y0 - 1000*(a))\n",
    "#             cv2.line(img,(x1,y1),(x2,y2),(100,100,100),2)\n",
    "    \n",
    "#     return img, lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_peaks(img, window, center):\n",
    "    axis0 = img.shape[0]\n",
    "    axis1 = img.shape[1]\n",
    "    center = -1\n",
    "    if(center == -1):\n",
    "        center = int(axis1/2)\n",
    "    \n",
    "    histogramL = np.sum(img[int(2*axis0/3):,:int(center)], axis=0)\n",
    "    histogramR = np.sum(img[int(2*axis0/3):,int(center):], axis=0)\n",
    "    peaksL = signal.find_peaks_cwt(histogramL,np.array([window]))\n",
    "    peaksR = signal.find_peaks_cwt(histogramR,np.array([window]))\n",
    "    if len(peaksR) > 0:\n",
    "        peaksR[0] += int(axis1/2)\n",
    "    \n",
    "    x2 = int(0.5*(int(axis0/3)+int(2*axis0/3)))\n",
    "    peaksLi = 0;\n",
    "    peaksRi = 0;\n",
    "    if len(peaksL) > 0:\n",
    "        peaksLi=int(np.mean(peaksL))\n",
    "#         cv2.circle(img, (peaksLi, x2), 10, (60,60,60) )\n",
    "    if len(peaksR) > 0:\n",
    "        peaksRi=int(np.mean(peaksR))\n",
    "#         cv2.circle(img, (peaksRi, x2), 10, (60,60,60) )\n",
    "    cornerL = 0;\n",
    "    cornerR = axis1;\n",
    "    if peaksLi > 0:\n",
    "        cornerL = peaksLi\n",
    "    if peaksRi > 0:\n",
    "        cornerR = peaksRi\n",
    "    \n",
    "    center=int((cornerL+cornerR)*0.5)\n",
    "    #cv2.circle(img, (center, x2), 15, (60,60,60) )\n",
    "    imgL = img[:,:center]\n",
    "    imgR = img[:,center:]\n",
    "    \n",
    "    return center, imgL, imgR\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_line(imgL, imgR, center, img, polyL, polyR):\n",
    "    xL,yL = np.nonzero(imgL)\n",
    "    xR,yR = np.nonzero(imgR)\n",
    "    \n",
    "    zL = np.polyfit(xL,yL, 1)\n",
    "    zR = np.polyfit(xR,(yR+center), 1)\n",
    "    PL = np.poly1d(zL)\n",
    "    PR = np.poly1d(zR)\n",
    "    \n",
    "    xP = range(0,imgL.shape[0],10)\n",
    "    yR = PR(xP)\n",
    "    for x,y in zip (xP,yR):\n",
    "        cv2.circle(img, (int(y),x), 10, (60,60,60))\n",
    "\n",
    "    yL=PL(xP)\n",
    "    for x,y in zip (xP,yL):\n",
    "        cv2.circle(img, (int(y),x), 10, (60,60,60) ) \n",
    "    \n",
    "    return img, zip(xP, yL), zip(xP, yR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_polynomial(imgL, imgR, center, img, polyL, polyR):\n",
    "    xL,yL = np.nonzero(imgL)\n",
    "    xR,yR = np.nonzero(imgR)\n",
    "    \n",
    "    if len(xL)>0:\n",
    "        polyL.fit(xL, yL)\n",
    "    if len(xR)>0:\n",
    "        polyR.fit(xR, (yR+center))\n",
    "    \n",
    "    xP = range(0,imgL.shape[0],10)\n",
    "    yR = polyR.ret(xP)\n",
    "    for x,y in zip (xP,yR):\n",
    "        cv2.circle(img, (int(y),x), 10, (60,60,60))\n",
    "\n",
    "    yL = polyL.ret(xP)\n",
    "    for x,y in zip (xP,yL):\n",
    "        cv2.circle(img, (int(y),x), 10, (60,60,60) )        \n",
    "    return img, zip(xP, yL), zip(xP,yR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_polynomial_by_points(img_length, XP, YP, img, polyP):\n",
    "    \n",
    "    polyP.fit(YP, XP)\n",
    "    yP = np.int32(range(0,img_length,10))\n",
    "    xP = np.int32(polyP.ret(yP))\n",
    "    for x,y in zip (xP,yP):\n",
    "        cv2.circle(img, (int(x),int(y)), 10, (60,60,60))\n",
    "        \n",
    "    return img, zip(yP, xP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def put_poly_to_opigin(img, Minv, poly_points_L, poly_points_R):\n",
    "    mask = np.zeros([img.shape[0], img.shape[1]])\n",
    "    for x,y in poly_points_R:\n",
    "        cv2.circle(mask, (int(y),x), 5, (255),5 )\n",
    "    for x,y in poly_points_L:\n",
    "        cv2.circle(mask, (int(y),x), 5, (255),5 ) \n",
    "    \n",
    "    mask = cv2.warpPerspective(mask, Minv, (img.shape[1], img.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    img[mask == 255] = (255, 0, 0, 0)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pixel_window(img, x_center, y_center, size):\n",
    "    half_size = int(size / 2)\n",
    "    window = img[y_center - half_size:y_center + half_size, x_center - half_size:x_center + half_size]\n",
    "    #ipdb.set_trace()\n",
    "    x, y = (window.T>50).nonzero()\n",
    "\n",
    "    x = x + x_center - half_size\n",
    "    y = y + y_center - half_size\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def detect_points_window(img, polyP, vertical_steps, center, global_img):\n",
    "    pixels_per_step = int(img.shape[0] / vertical_steps)\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    if polyP.is_fitted():\n",
    "        for i in range(vertical_steps):\n",
    "            #ipdb.set_trace()\n",
    "            start_window = img.shape[0] - (i * pixels_per_step)\n",
    "            end_window = start_window - pixels_per_step\n",
    "\n",
    "            local_center = int((start_window + end_window) / 2)\n",
    "            x = polyP.ret(local_center)-center\n",
    "            x, y = get_pixel_window(img, int(x), int(local_center), pixels_per_step)\n",
    "            all_x.extend(x+center)\n",
    "            all_y.extend(y)\n",
    "\n",
    "            \n",
    "                \n",
    "        for x_,y_ in zip(all_x,all_y):\n",
    "            cv2.circle(global_img, (x_ ,y_), 2, (4),2)\n",
    "        \n",
    "    return all_x, all_y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test avaliable USB devices\n",
    "CHECK_CAMS = False\n",
    "\n",
    "if(CHECK_CAMS):\n",
    "    cams_test = 5\n",
    "    for i in range(0, cams_test):\n",
    "        cap = cv2.VideoCapture(i)\n",
    "        test, frame = cap.read()\n",
    "        if test:\n",
    "            print(\"device number: \"+str(i)+\" -> result: \"+str(test))\n",
    "        \n",
    "CAM_DEVICE=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SOURCE = 'samples/test.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VIDEO_SOURCE = 'samples/testvideo2.mp4'\n",
    "VIDEO_SOURCE = 'samples/project_video.mp4'\n",
    "#VIDEO_SOURCE = 'samples/Autobahn.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_source = 'image'\n",
    "# datasource = 'camera'\n",
    "data_source = 'video'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260\n",
      "setting projection\n",
      "531\n",
      "1440\n",
      "[[ 251  644]\n",
      " [ 548  451]\n",
      " [ 698  448]\n",
      " [1160  644]]\n",
      "[(531, 720), (531, 0), (880, 0), (880, 720)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noctum/anaconda2/lib/python2.7/site-packages/scipy/optimize/minpack.py:785: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projection with corrected horizon\n",
      "531\n",
      "1440\n",
      "[[ 251  644]\n",
      " [ 548  451]\n",
      " [ 698  451]\n",
      " [1160  644]]\n",
      "[(531, 720), (531, 0), (880, 0), (880, 720)]\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "play_video = True\n",
    "delta_window = 30;\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('origin', cv2.WINDOW_NORMAL)\n",
    "polyL = poly_fixed_der(derivative_value=0)\n",
    "polyR = poly_fixed_der(derivative_value=0)\n",
    "\n",
    "\n",
    "if data_source=='camera':\n",
    "    cap = cv2.VideoCapture(CAM_DEVICE)\n",
    "elif data_source=='video':\n",
    "    cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "    cv2.resizeWindow('image', 640,380)\n",
    "    cv2.resizeWindow('origin', 640,380)\n",
    "    video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(video_length)\n",
    "elif data_source=='image':\n",
    "    test_image = cv2.imread(IMAGE_SOURCE)\n",
    "    cv2.resizeWindow('image', 640,380)\n",
    "    cv2.resizeWindow('origin', 640,380)\n",
    "    \n",
    "cv2.setMouseCallback('image',draw_rectangle)\n",
    "set_mapping=False\n",
    "thresh1=50;\n",
    "thresh2=130;\n",
    "thresh=150;\n",
    "video_fames=0;\n",
    "center = -1;\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    if data_source=='camera':\n",
    "        ret, frame = cap.read()\n",
    "    elif (data_source=='video')&(play_video):\n",
    "        video_fames+=1\n",
    "        if(video_fames==video_length-1):\n",
    "            cap = cv2.VideoCapture(VIDEO_SOURCE)\n",
    "            video_fames=0\n",
    "            print('video restarted')\n",
    "        ret, frame = cap.read()\n",
    "    elif data_source=='image':\n",
    "        frame = test_image\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    color = cv2.cvtColor(frame, cv2.COLOR_RGB2RGBA ) # cv2.COLOR_RGB2RGBA\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) # cv2.COLOR_RGB2RGBA\n",
    "    # Display the resulting frames\n",
    "    \n",
    "    gray1 = cv2.warpPerspective(gray, M, (gray.shape[1], gray.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "   \n",
    "    \n",
    "    \n",
    "    if set_mapping:\n",
    "        pnts_map = cv2.perspectiveTransform(np.array([pnts], dtype='float32'), M)\n",
    "        pnts_map=np.int32(pnts_map[0])\n",
    "        edges = detect_edges(gray1, pnts_map, thresh1, thresh2, thresh)\n",
    "        # cv2.polylines(edges,[pnts_map],True,(255,255,255),0)\n",
    "        py_min=min(pnts_map[0][1],pnts_map[3][1])\n",
    "        py_max=max(pnts_map[1][1],pnts_map[2][1])\n",
    "        px_min=min(pnts_map[0][0],pnts_map[1][0])\n",
    "        px_max=max(pnts_map[2][0],pnts_map[3][0])     \n",
    "        snip = edges#[py_max:py_min, px_min-delta_window:px_max+delta_window]\n",
    "        # snip1, lines = get_pointsP(snip)\n",
    "        center, imgL, imgR = get_peaks(snip, 6, center);\n",
    "        x_zero_point=imgL.shape[0]\n",
    "        \n",
    "        polyL.set_zero_x_point(x_zero_point)\n",
    "        polyR.set_zero_x_point(x_zero_point)\n",
    "\n",
    "        XL, YL = detect_points_window(imgL, polyL, 5, 0, snip)\n",
    "        XR, YR = detect_points_window(imgR, polyR, 5, center, snip)\n",
    "    \n",
    "        if(len(XR)<10) | (len(XL)<10):\n",
    "            snip, poly_points_L, poly_points_R = fit_polynomial(imgL, imgR, center, snip, polyL, polyR)\n",
    "        else:\n",
    "            snip, poly_points_L = fit_polynomial_by_points(imgL.shape[0], XL, YL, snip, polyL)\n",
    "            snip, poly_points_R = fit_polynomial_by_points(imgR.shape[0], XR, YR, snip, polyR)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        color = put_poly_to_opigin(color, Minv, poly_points_L, poly_points_R)\n",
    "        gray1=snip\n",
    "\n",
    "    \n",
    "    \n",
    "    pnts=np.array(pnts);\n",
    "    cv2.polylines(gray1,[pnts],True,(0,255,255))\n",
    "    # show images\n",
    "    cv2.imshow('origin',color)\n",
    "    cv2.imshow('image',gray1)\n",
    "    \n",
    "    #working with keys\n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord('1'):\n",
    "        thresh1+=1\n",
    "    elif key & 0xFF == ord('2'):\n",
    "        thresh1-=1\n",
    "    elif key & 0xFF == ord('3'):\n",
    "        thresh2+=1\n",
    "    elif key & 0xFF == ord('4'):\n",
    "        thresh2-=1  \n",
    "    elif key & 0xFF == ord('5'):\n",
    "        thresh+=1\n",
    "    elif key & 0xFF == ord('6'):\n",
    "        thresh-=1  \n",
    "    elif key & 0xFF == ord('q'):\n",
    "        print \"quit\"\n",
    "        break\n",
    "    elif (key & 0XFF == ord('p'))&(data_source=='video'):\n",
    "        play_video = not play_video\n",
    "    elif (key & 0xFF == ord('s'))&(set_poly==False):\n",
    "        print \"projection with corrected horizon\"\n",
    "        pnts[2][1]=pnts[1][1]\n",
    "        pnts[3][1]=pnts[0][1]\n",
    "        (M,Minv) = translate_coordinates(pnts, color.shape);\n",
    "        set_mapping = True\n",
    "    elif (key & 0xFF == ord('w'))&(set_poly==False):\n",
    "        print \"setting projection\"\n",
    "        (M,Minv) = translate_coordinates(pnts, color.shape);\n",
    "        set_mapping = True\n",
    "    elif key & 0xFF == ord('i'):\n",
    "        print \"setting inverse projection\"\n",
    "        E=Minv;\n",
    "        Minv=M;\n",
    "        M=E;\n",
    "    elif key & 0xFF == ord('r'):\n",
    "        print \"reset\"\n",
    "        M=np.eye(3,3)\n",
    "        Minv=M;\n",
    "        click=0;\n",
    "        set_poly=True;\n",
    "        pnts = [[0,0],[0,0],[0,0],[0,0]]\n",
    "        set_mapping=False\n",
    "    elif key & 0xFF == ord('e'):\n",
    "        print \"identity projection\"\n",
    "        M=np.eye(3,3)\n",
    "        Minv=M;\n",
    "        \n",
    "    \n",
    "# When everything done, release the capture\n",
    "if data_source!='image':\n",
    "    cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
